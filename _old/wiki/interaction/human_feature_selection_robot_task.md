# Human-driven feature selection for a robot learning classification tasks from demonstration

```
@inproceedings{bullard2018human,
  title={Human-driven feature selection for a robot learning classification tasks from demonstration},
  author={Bullard, Kalesha and Chernova, Sonia and Thomaz, Andrea L},
  booktitle={Robotics and Automation (ICRA), 2012 IEEE International Conference on. IEEE},
  year={2018}
}
```

## One Sentence
This paper how humans can teach robot in an object recognition task by either suggesting discriminative features or providing representative examples, and found that while automatic feature selection still triumps with sufficient amount of data, directly communicating features is most effective when there is little training data available.

## More Sentences
The research questions:
> "(a) whether a domain expert is able to identify a subset of features that will enable the robot to classify unseen examples as accurately as using computational feature selection and (b) if the interaction strategy used to elicit the information from the user impacts the quality of resulting feature selection."

## Key Points
Compared to other approaches
> "... little prior work considers feature selection in the context of deploying a general-purpose robot able to learn new tasks."

> "... incorporating too many uncessary features leads to poor learning performance."

> "Computational feature selection techniques, which rely on identifying statistical patterns in data, may not have sufficient evidence given the small number of training examples encountered in LfD [learning from demonstration]"

The study conditions
- Human feature selection
- Human feature reduction
- Human instance selection

  * Additional feature selection
  * Additional feature reduction

Hypothesis
> "We hypothesized that people would be more adept at indirectly communicating features because some candidate features generated by the robots' sensors may not be as intuitive for people."

Summary of findings:
> "... with a small amount of training data, we observe that allowing a human teacher to provide feature information about the task yields a statistically significant increase in expected learning performance as compared to using only a computational FS approach"


Unsorted
> "... people are able to select useful features for a task only when the features are semantically interpretable."

## Take-away
* It seems the features are (intentionally) too noisy, adding difficulty for automatic feature selection. With a better initial feature set, perhaps the automatic process can perform well even with few data points.