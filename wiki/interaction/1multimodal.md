# Multimodal Interaction

* Kendon, A., 1980. 
[**Gesticulation and speech: Two aspects of the process of utterance**](kendon_gesticulation_speech.md) 
The relationship of verbal and nonverbal communication, 25(1980), pp.207-227.

* Cohen, P.R., Darlymple, M., Pereira, F.C.N., Sullivan, J.W., Gargan Jr, R.A., Schlossberg, J.L. and Tyler, S.W.
[**Synergic use of direct manipulation and natural language**](cohen_synergic_direct_manipulation_natural_language.md)
In Proc. Conf. human Factors in Computing Systems (CHI'89) (pp. 227-233).

* Neal, J.G., Thielman, C.Y., Dobes, Z., Haller, S.M. and Shapiro, S.C., 1989, October. 
[**Natural language with integrated deictic and graphic gestures**](neal_natural_language_deictic_graphic.md)
In Proceedings of the workshop on Speech and Natural Language (pp. 410-423). Association for Computational Linguistics.

* Schmandt, C., Ackerman, M.S. and Hindus, D., 1990. 
[**Augmenting a window system with speech input**](schmandt_aug_win_speech_input.md)
Computer, 23(8), pp.50-56.

* Cohen, P.R., Johnston, M., McGee, D., Oviatt, S., Pittman, J., Smith, I., Chen, L. and Clow, J.
[**QuickSet: Multimodal interaction for distributed applications**](cohen_quickset.md)
In Proceedings of the fifth ACM international conference on Multimedia (pp. 31-40). ACM.

* Fukumoto, M., Suenaga, Y. and Mase, K., 1994. 
[**“Finger-Pointer”: Pointing interface by image processing**](fukumoto_finger_pointer.md)
Computers & Graphics, 18(5), pp.633-642.

* Vo, M.T. and Wood, C., 1996.
[**Building an application framework for speech and pen input integration in multimodal learning interfaces**](vo_joint_interpretation_multimodal.md)
In Acoustics, Speech, and Signal Processing, 1996. ICASSP-96. Conference Proceedings., 1996 IEEE International Conference on (Vol. 6, pp. 3545-3548). IEEE.

* Oviatt, S., Cohen, P., Wu, L., Duncan, L., Suhm, B., Bers, J., Holzman, T., Winograd, T., Landay, J., Larson, J. and Ferro, D.
[**Designing the user interface for multimodal speech and pen-based gesture applications: state-of-the-art systems and future research directions**](oviatt_designing_mmodal_speech_pen_gesture_app.md)
Human-computer interaction, 15(4), pp.263-322.

* Sigrist, R., Rauter, G., Riener, R. and Wolf, P., 2013. 
[**Augmented visual, auditory, haptic, and multimodal feedback in motor learning: a review**](sigrist_multimodal_output.md) 
Psychonomic bulletin & review, 20(1), pp.21-53.

* Setlur, V., Battersby, S.E., Tory, M., Gossweiler, R. and Chang, A.X.
[**Eviza: A Natural Language Interface for Visual Analysis**](seltur_eviza.md)
In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (pp. 365-377). ACM.
