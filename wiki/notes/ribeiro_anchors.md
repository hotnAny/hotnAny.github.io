# Anchors: High-precision model-agnostic explanations
```
@inproceedings{ribeiro2018anchors,
  title={Anchors: High-precision model-agnostic explanations},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2018}
}
```

## One Sentence
This paper proposes a method to sample training data and generate sufficiently accurate explanation of an intelligent system's behavior.

## Key Points
> "In a user study, we show that anchors enable users to predict how a model would behave on unseen instances with less effort andhigher precision"

> "A question at the core of interpretability is whether humans understand a model enough to make accurate predictions about its behavior on unseen instances"

## Take-Away
* Globally-interpretable machine learning models: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5108651/
