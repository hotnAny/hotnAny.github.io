<body>
	<link rel="stylesheet" href="style.css" />
	<link href="https://fonts.googleapis.com/css?family=Alegreya+Sans:400,700" rel="stylesheet">

	<table width="50%">
		<tr>
			<td>
				<a href="image/xac.jpg" target="_blank">PHOTO</a>
				<br /><br />
			</td>
		</tr>

		<tr>
			<td>
				<b>TITLE </b>
				<br />
				Expanding the Interaction Bandwidth between Human and AI
				<br /><br />
			</td>
		</tr>

		<tr>

			<td>
				<b>ABSTRACT </b>
				<br />
				The recent development of artificial intelligence (AI) promises a future of data-driven automation that can replace most of today’s human efforts. However, currently most AI-enabled systems—often functioning as ‘black boxes’—struggle to accommodate, learn from or communicate with humans. One fundamental problem is a limited interaction bandwidth between human and AI: currently, AI’s development is bestowed upon the few experts; for users in non-computing domains, there is limited support for them to comprehend, control or collaborate with AI. As we are on the cusp of defining the future of human-AI relationship, it is important to create new interaction channels to bridge AI and non-computing users. In this talk, I will discuss three research thrusts for expanding the interaction bandwidth between human and AI:
				<ul>
					<li>
						Human ← AI: making AI comprehensible to non-computing domain users. Going beyond system-centered prior work that focused on generic explainable representations of AI (XAI), my research takes a 
						user-centered approach: for example, CheXplain is a system co-designed via iterative studies with medical professionals, which enables referring physicians to explore and understand AI-generated 
						diagnosis on chest X-ray images.
					</li>
					<li>
						Human → AI: enabling non-computing domain users to control AI. Contrary to providing a single label, my research investigates techniques for users to express their domain knowledge in ways that are understandable and learnable to an AI: for example, Forte is a tool for mechanical engineers using sketching to customize topology optimization---a generative process that automatically creates mechanical designs based on functional constraints.
					</li>
					<li>
						Human ↔ AI: supporting collaboration between non-computing domain users and AI. Building upon comprehensible and customizable AI, my research takes an integrated approach that creates an 
						environment to support human-AI collaboration: for example, PathoLogic is a tool that enables pathologists to 'shepherd' a team of AI, i.e., delegating low-level examination of different criteria to AI models while using the tool to visualize and verify AI's results.

					</li>
				</ul>

			</td>
		</tr>

		<tr>
			<td>
				<b>BIO</b>
				<br />
				Xiang ‘Anthony' Chen is an Assistant Professor in UCLA's Department of Electrical & Computer Engineering. Anthony's area of expertise is Human-Computer Interaction (HCI). He received his Ph.D. in the School of Computer Science at Carnegie Mellon University and was a recipient of the ONR Young Investigator Award, NSF CAREER Award, Hellman Fellowship, NSF CISE CRII Award and Adobe Ph.D. Fellowship. His research is at the intersection of sensing & interaction techniques, intelligent user interfaces, and computational design & fabrication. Anthony’s work has won two best paper awards and two honorable mentions in top-tier HCI conferences.
				<br/>
				<br/>
				陈翔是加州大学洛杉矶分校电气与计算机工程系的助理教授。 他的专长领域是人机交互 (HCI)。他在卡内基梅隆大学计算机科学学院获得博士学位，还获得过ONR Young Investigator Award、NSF CAREER Award、Hellman Fellowship、NSF CISE CRII Award 和 Adob​​e Ph.D.奖学金。他的研究领域是传感与交互技术、智能用户界面以及计算设计与制造的交叉领域。 陈翔的工作在顶级 HCI 会议中获得了两项最佳论文奖和两项荣誉提名。
			</td>
		</tr>

	</table>


</body>