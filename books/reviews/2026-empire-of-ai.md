I listened to the audiobook version.

Overall, this is a book we need. Both the AI community and the broader public benefit from its critical lens, which invites a level-headed reflection on AI hype, the costs behind its advances, and the tendency to take these systems for granted.

I’ve read other sociotechnical books on AI, including [*The Alignment Problem*](https://en.wikipedia.org/wiki/The_Alignment_Problem) and [*Superintelligence*](https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies). This book differs from them in an important way: it is largely grounded in investigative journalism. As a result, many of its arguments are supported by first-hand evidence rather than speculative reasoning. That grounding makes the more opinionated parts of the book feel concrete and anchored in reality.

Several parts of the book stood out to me.

**Data Labor**
The book documents data workers who earn very low wages performing labor-intensive tasks such as cleaning internet text that may contain toxic content. Beyond highlighting low pay, it presents stories of these workers—their backgrounds, how they ended up in these roles, and the conditions under which they work. It also notes that the companies benefiting from this labor could afford to pay more, but generally choose not to.

**Environmental Costs**
that include both training and inference. These processes rely on large data centers that leave a significant environmental footprint. The book describes how data centers generate persistent noise that affects nearby residents, and how their cooling systems require large amounts of purified water. In regions such as Arizona and Chile, this creates direct competition between data centers and local communities for limited water resources.

**Internal Conflicts Within AI Companies**
The book also discusses internal struggles within AI companies, most notably the episode surrounding Sam Altman’s removal. It highlights tensions between non-profit and for-profit orientations, between AI “doomers” and “bloomers,” and between different styles of governance and management. These conflicts help contextualize how decisions about safety, research, and deployment are made.

These issues—labor conditions, environmental impact, and internal power struggles—are largely invisible in everyday interactions with large language models. When we casually send a prompt to ChatGPT, we rarely consider the human labor involved, the environmental resources consumed, or the internal negotiations that shape what the system does or does not allow. One of the book’s main contributions is making these hidden dimensions more visible.

My main criticism concerns the book’s focus on matters involving Sam Altman’s sister. This material feels personal and private, and its inclusion strikes me as inconsistent with the rest of the book’s tone and standards.
More importantly, the connection to OpenAI is unclear. While Altman is involved in both family and professional contexts, the book does not provide evidence or a strong argument showing how his behavior in one context relates to the other. The implied linkage often feels vague, and the juxtaposition of private family matters with OpenAI’s institutional affairs weakens the otherwise grounded analysis.