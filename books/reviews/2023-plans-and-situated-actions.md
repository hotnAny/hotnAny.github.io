<!-- 2023-plans-and-situated-actions -->

To achieve any purposes (including interacting with computers to accomplish a task), there are two approaches: 1) making a plan, executing it, and modifying it along the way if necessary; or 2) knowing the objective, take "situated actions" (see below) towards it. The author of this book attempts to reconcile these two approaches.

The author is a sociologist and, expectedly, the main shortcoming of this book is lack of grounding in the details of designing and implementing an interactive intelligent machines. Most take-away messages sound insightful yet remain vague unless you go the extra (100) miles to interpret it in the process of designing and implementing an interactive intelligent machine.

I, in particular, dislike the style of writing in this book. The writing seems intentionally hard to understand. It's very effortful trying to decipher the gist behind the abstractness and verbosity, not to mention translating any insight thereof into concrete and meaningful actions.

For what it's worth, this book means more to people working on voice assistants or dialog-based interaction between humans and computers, rather than the general audience that design interactions between humans or intelligent machines. As the author emphasizes situated actions that are unplanned, thus the need to recognize certain situations and to interpret either the human's or the machine's intents.

The **main take-away for designing human-AI collaboration** is that we need both plans and situated actions. A plan serves as a prescribed framework that coordinate human and AI to work together: do this first, by AI, then do that, by human, etc. Such a plan is carried out in real-time as situated actions where the plan serves as resources, combined with the recognized intents and environmental parameters, to formulate actions being taken by humans or AI. A plan on its own is insufficient to enable human-AI collaboration, it needs to be 'filled in' with situated actions that take place in real-time.

# Introduction

What is situated actions?
> By situated actions I mean simply actions taken in the context of particular, concrete circumstances.

> I take the idea that actions are primarily situated, and that situated actions are essentially ad hoc, as the starting point for my investigation


> My central concern in the investigation is a new manifestation of an old problem in the study of mutual intelligibility: namely, the relation between observable behavior and the processes, not available to direct observation, that make behavior meaningful.

One's behavior reflects their meaning and intent, which are expressed in behavior.
> ... the problem of meaningful action turns on the observation that behavior is inherently subject to indefinitely many ascriptions of meaning or intent, while meaning and intent are expressible through an indefinite number of possible behaviors.

How we can use appropriate behavior to frame the goal of machines:
> ... the goal is just a machine that, given some input, produces behavior that is useful and appropriate to the situation at hand. ... insofar as rightness or appropriateness of behavior means that behavior is accountably rational in the eyes of an other, the measure of success is at bottom in interactional one.

The author's main thesis on plans and situated actions
> ... examine an artifact built on a *planning model* of human action. The model treats a plan as something located in the actor's head, which directs his or her behavior. In contrast, I argue that artifacts built on the planning model confuse *plans* with *situated actions*, and recommend instead a view of plans as formulations of antecedent conditions and consequences of action that account for action in a plausible way.

Interaction, communication, and mutual intelligibility
> ... interaction or communication ... use two terms interchangeably ... as the mutual intelligibility of action, ...

> Interaction between people and machines implies mutual intelligibility, or shared understanding.

# Artifacts

On explanation
> ... the description of computational artifacts as interactive is supported by their reactive, linguistic, and internally *opaque* properties. ... the double sense in which researchers are interested in artifacts that explain themselves: on the one hand, as a solution to the longstanding problem of conveying the artifact's intended purpose to the user, through its design and attendant instructions and, on the other hand, as a means of establishing the intelligence, or rational accountability, of the artifact itself.

The author's take on cognitive science
> The first premise of cognitive science, therefore, is that people - or "cognizers" of any sort - act on the basis of symbolic representations: a kind of cognitive code, instantiated physically in the brain, on which operations are performed to produce mental states such as "the belief that *p*", which in turn produce behavior consistent with those states.

On human-machine communication being linguistic
> ... the means for controlling computing machines and the behavior that results are increasingly *linguistic*, rather than mechanistic. That is to say, machine operation becomes less a matter of pushing buttons or pulling levers with some physical result, and more a matter of specifying operations and assessing their effects through the use of common language.

On the key difficulties of enabling human-machine communication
> [Hayes and Reddy (1983)] identify the central difference between existing interactive computer systems and human communication as a question of "robustness," or the ability on the part of conversational participants to respond to unanticipated circumstances, and to detect and remedy troubles in communication.

Why human language might not be the best language to communicate with machines
> ... Fitter (1979) to argue that English or other "natural" languages are in fact not natural for purposes of human-computer interaction

What Fitter said:
> ... for the purpose of man-computer communication, *a natural language is one that makes explicit the knowledge and processes for which the man and computer share a common understanding ...*

Computer as a tool not a person
> ... Nickerson (1976) argues that: 
The model that seems appropriate for this view of person-computer interaction is that of an individual making use of a sophisticated tool and not that of one person conversing with another.

A 'reconstructive' view of explainability
> ... the degree to which an artifact is self-explanatory is just the extent to which someone examining the artifact is able to reconstruct the *designer's intentions* regarding its use.

Where human-computer conversation often fails
> During the course of a conversation, it is not uncommon for people to misunderstand or fail to understand each other. Such failures in communication do not usually cause the conversation to break down; rather, the participants are able to resolve the difficulty.

# Plans

The three backbone theories of plans
> ... (1) the planning model itself, which takes the significance of action to tbe derived from plans, and identifies the problem for interaction as their recognition and coordination, (2) speech act theory, which accounts for the recognizability of plans or intentions by proposing conventional rules for their expression, and (3) the idea of shared background knowledge, as the common resource that stands behind individual action and gives it social meaning.

What is a planning model
> The planning model in cognitive science treats a plan as a sequence of actions designed to accomplish some preconceived end. The model posits that action is a form of problem solving, where the actor's problem is to find a path from some initial state to a desired goal state, given certain conditions along the way.

# Other Quotes
Computers raise our awareness
> In *The Second Self* (1984), Sherry Turkle describes the computer as an "evocative object", one that raises new questions regarding our common sense of the distinction between artifacts and intelligent others.

# Random Thoughts
Is human-AI collaboration a problem of plans or situated actions?

Mutual intelligibility between humans and machines

Some above-mentioned paper links:
* https://www.sciencedirect.com/science/article/abs/pii/S0020737379800292
* https://dl.acm.org/doi/pdf/10.1145/1024273.1024286
* https://www.jstor.org/stable/1466895