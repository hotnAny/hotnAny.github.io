<!-- 2023-the-alignment-problem -->

This is the most important book I read in 2023.

There has been an increasing awareness of AI’s alignment problem in the research community but I don’t think there is yet a holistic understanding (or discussion) of what alignment means and what kinds of problems alignment research should encompass.

This book does exactly just that. It covers such a wide range of traditional and recent AI methods and delves into some of the most sensitive issues, such as fairness, transparency, and agency. Not only does it provide a layman-friendly description of each method and issue, the book also reflects on and questions each approach, often via a discussion with the related AI researchers. The author often employs a “yes, but” type of tone, never satisfied with how good an AI method can achieve and always pointing out unnoticed cases that will eventually reveal a method’s pitfall.

One main doubt I have about the book is whether there is enough focus on “value”, which is right there in the book’s subtitle (“How can Artificial Intelligence Learn Human Values?”). The majority of the discussions seem to ask whether AI can learn human intelligence, which is not necessarily value.

Nonetheless, this is book that, minimally can educate any non-technical readers about AI, and maximally can motivate one to take a similarly critical stance to examine their work involving AI.