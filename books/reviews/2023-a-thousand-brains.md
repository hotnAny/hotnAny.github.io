<!-- 2023-a-thousand-brains -->

I had high hope for this book, having been impressed by the author's previous work "On Intelligence". However, I became more skeptical of his theory after reading this book. First, it's unclear how much is new and different than his previous book's. Second, I don't quite get the 'reference frame' theory. Although I get the simplified example of searching on a map, I fail to convince myself that such a metaphor is applicable to our brain (or how). Third, after reading this [critic](https://www.toutiao.com/article/7201288095407899140/) I increasingly feel the author clings too much to Mountcastle's hypothesis (e.g., cortical columns) and has not quite updated his knowledge with new studies or findings (maybe he simply dismissed them?).

I haven't read much of reviews or critics' comments on the author's work but I guess the main challenge would be a lack of experiments or validation of the proposed framework. If this framework is *the* answer to the intelligence question, why shouldn't we already have already implemented such intelligence?

I disagree with the author that artificial neural networks (ANNs) totally avoid any principles of how human brains work. I think ANNs probably do a pretty good job simulating some low-level structure of our brain, e.g., how layers of neurons together (as a "column", using this book's term) can recognize images. But the problem is that our brain is much more than that in the sense that such structure is merely a microscopic building block of a much more complex, unknown mechanism in our brain that makes us intelligent.

Does AI have to mimic the brain to be truly intelligent? This remains a philosophical argument until someone actually re-invents intelligence (one way or another). Although the author firmly believes so, one can easily find counter-examples, such as how airplanes successfully achieves flying without fully mimicking birds (no flapping wings).

The kind of intelligence discussed in this book (or maybe also the predecessor "On Intelligence") remains narrow, mainly limited to recognizing objects and places. How about the intelligence of solving math problems, the intelligence of creating art, or the intelligence of empathizing with another human being?

I do find the visioning of intelligent systems exploring the vast universe fascinating. At the time I read this chapter, I just finished "Existential Physics" that really piqued my interest wanting to know the "secrets' of the universe. However, I didn't put together such interest and AI until seeing Hawkins' proposal. It also reminds me of how the famous sci-fi story about a machine calculated "42" as the answer to the "ultimate question of life, the universe, and everything".

The author firmly believes that intelligent machines will not threaten humans' existence. One of the reasons is how such machine intelligence will not "explode" exponentially to overwhelm us:
> We can endow a machine with the ability to learn a model of the world, but the knowledge that makes up that model has to be learned, and learning takes time. ... although we can make intelligent machines that run a million times faster than a biological brain, they cannot acquire new knowledge a million times faster.

I find parts of the book lacks rigor. For example, the author tries to explain the behaviors of flat-earth believers and climate change deniers using how their brains develop an incorrect model of the world. There are two problems with this argument. First, the brain's model that has been mentioned so far in this book is only concerned with humans' innate abilities, such as recognizing objects and places. Such an ability to model facets of the physical world serves as building blocks for us to learn higher-level concepts, such as formulating a mental model of a rounded earth. However, the specific approaches of formulating high-level concepts might be different from the low-level modeling of the physical world. It lacks rigor to simply equate the two because there is the word "model" in both cases. Second, the author ignores the possibilities that people might choose to knowingly accept an incorrect model due to other motivations, such as political or financial ones. Such ignorance seems ironic given how the author just mentioned in the earlier chapter that humans differ from machines by being able to develop motivations.

The birth control example is an interesting one to illustrate the relationship between our old and new brain. While the old brain wants us to have sex and procreate, the new brain invents birth control to 'trick' the old brain---have as much sex as you want with little risk of over-procreation.

The segway at the end of Chapter 14 to the existential crisis of humanity is a little out of the blue. But maybe not. The author cares about brains because our brains make us who we are. We want to live as individuals and a species because our brains have evolved to enable us to accomplish so much. Thus it is natural to be concerned about any crisis that might prevent our brains from existing.

Two things I quite appreciate near the end of the book. 

First, the author shows how we can think of ourselves in an 'out-of-the-body' way as being dominated by the co-existence of the new and old brains. I see how it is possible to look at our own behavior and say, "This is the old brain working!" This makes me feel as if I had a 'meta brain' that can think independently of the old and new brains. 

Second, obviously the author has been concerned with much bigger problems than our brain, such as the destiny of the human race. Some speculations are really interesting, though borderline science fiction, such as sending messages via orbiting satellites and replicating ourselves as equivalent intelligent machines capable of interstellar travel. What I appreciate the most is how the author's realization that passing our genes, as we have been doing for generations, is not as important as passing on the knowledge we have discovered and created. It is knowledge, not genes, that defines our identity and value.

